model:
  architecture: llama
  attention_bias: false
  bos_token_id: 1
  eos_token_id: 2
  activation: silu
  hidden_size: 2048
  initializer_range: 0.02
  intermediate_size: 5632
  max_seq_len: 2048
  n_heads: 32
  n_layers: 16
  n_kv_heads: 4
  rms_norm_eps: 1.0e-05
  rope_theta: 10000
  tie_word_embeddings: false
  torch_dtype: bfloat16
  use_cache: true
  ffn_dim_multiplier: 1.3
  multiple_of: 1024
  vocab_size: 32000

tokenizer:
  tokenizer_type: huggingface
  tokenizer_name_or_path: meta-llama/Llama-2-7b-chat-hf

checkpoint:
  ckpt_dir: .local/ckpts
  create_seed_checkpoint: false
  finetuned_from: TinyLlama/TinyLlama_v1.1
  interval: 2000
  async_mode: async
  export_dtype: bfloat16

training:
  gc_freq: 1000
  dp_degree: 2
  tp_degree: 1
  pp_degree: 1
  enable_loss_parallel: true
  data_parallel_type: fsdp
  dump_folder: ./outputs
  train_steps: 100000
  warmup_steps: 2000
  ac_mode: selective
  cpu_offload: false
  selective_ac_option: "2"
  compile: false

dataset:
  name: HuggingFaceFW/fineweb-edu
  stream: true
  seq_len: 2048
  batch_size: 4

metrics:
  enable_wb: true
  log_freq: 1
  project_name: fmengine-dev
  project_group: stf-3090
  project_id: stf-3090-testrun


profiling:
  profile_freq: 500

optimizer:
  name: adamw
  lr: 1e-3
  fused: true